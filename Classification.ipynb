{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"http://www.cs.wm.edu/~rml/images/wm_horizontal_single_line_full_color.png\">\n",
    "    <h1>CSCI 416-01/516-01, Fall 2024</h1>\n",
    "    <h1>Building a classifier for the 2016 presidential election</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMMY MARTINEZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* [The problem](#The-problem)\n",
    "* [The data](#The-data)\n",
    "* [To do](#To-do)\n",
    "* [What to submit](#What-to-submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "In this problem you will look at county-level data for the 2016 presidential election (\"county\" is used loosely here, e.g., Virginia has independent cities that are included as counties).\n",
    "\n",
    "The goal is to build a classifier to determine whether a county voted for Hilary Clinton or for Donald Trump.\n",
    "\n",
    "The demographic and geographic features for each county are listed below.\n",
    "\n",
    "An interesting feature of the election is the so-called [Clinton Archipelago](https://vividmaps.com/trumpland-and-clinton-archipelago): Clinton carried relatively few counties compared to Trump (but they were counties with large populations):\n",
    "<pre>\n",
    "County breakdown:  your data  my test set    total\n",
    "         Clinton         330          158      488\n",
    "         Trump          1670          954     2624\n",
    "       \n",
    "</pre>\n",
    "\n",
    "The simplest classifier we can build from the training data would be to say all counties vote Trump.  This classifier would be correct for  \n",
    "$$\n",
    "  1 - \\frac{330}{330 + 1670} = 83.5\\%\n",
    "$$\n",
    "of the data you are provided, and\n",
    "$$\n",
    "1 - \\frac{158}{158 + 954} = 85.8\\%\n",
    "$$\n",
    "of my test cases!  So whatever classifier you build must be substantially better than the majority class classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data\n",
    "\n",
    "The data you have to work with are in [<code>vote16_classification.csv</code>](http://www.cs.wm.edu/~rml/teaching/csci416/midterm/vote16_classification.csv).  This is a CSV file.\n",
    "\n",
    "Column 0 is the class label:\n",
    "<pre>\n",
    "0: won by Clinton\n",
    "1: won by Trump\n",
    "</pre>\n",
    "\n",
    "The next column is\n",
    "<pre>\n",
    "state_abbr:  the state's abbreviation\n",
    "</pre>\n",
    "\n",
    "These are followed by information about the 2012 election, including the proportion voting for Obama and Romney as well as the vote totals themselves:\n",
    "<pre>\n",
    "total_votes_2012: total number of votes cast in the 2012 election\n",
    "votes_dem_2012:   number of votes cast for the Democratic candidate in 2012\n",
    "votes_rep_2012:   number of votes cast for the Republican candidate in 2012\n",
    "Obama:            percentage voting for Obama in 2012\n",
    "Romney:           percentage voting for Romney in 2012\n",
    "</pre>\n",
    "\n",
    "The remaining columns are demographic data about the geographical unit:\n",
    "<pre>\n",
    "PST045214: Population, 2014 estimate\n",
    "PST040210: Population, 2010 (April 1) estimates base\n",
    "PST120214: Population, percent change - April 1, 2010 to July 1, 2014\n",
    "POP010210: Population, 2010\n",
    "AGE135214: Persons under 5 years, percent, 2014\n",
    "AGE295214: Persons under 18 years, percent, 2014\n",
    "AGE775214: Persons 65 years and over, percent, 2014\n",
    "SEX255214: Female persons, percent, 2014\n",
    "RHI125214: White alone, percent, 2014\n",
    "RHI225214: Black or African American alone, percent, 2014\n",
    "RHI325214: American Indian and Alaska Native alone, percent, 2014\n",
    "RHI425214: Asian alone, percent, 2014\n",
    "RHI525214: Native Hawaiian and Other Pacific Islander alone, percent, 2014\n",
    "RHI625214: Two or More Races, percent, 2014\n",
    "RHI725214: Hispanic or Latino, percent, 2014\n",
    "RHI825214: White alone, not Hispanic or Latino, percent, 2014\n",
    "POP715213: Living in same house 1 year & over, percent, 2009-2013\n",
    "POP645213: Foreign born persons, percent, 2009-2013\n",
    "POP815213: Language other than English spoken at home, pct age 5+, 2009-2013\n",
    "EDU635213: High school graduate or higher, percent of persons age 25+, 2009-2013\n",
    "EDU685213: Bachelor's degree or higher, percent of persons age 25+, 2009-2013\n",
    "VET605213: Veterans, 2009-2013\n",
    "LFE305213: Mean travel time to work (minutes), workers age 16+, 2009-2013\n",
    "HSG010214: Housing units, 2014\n",
    "HSG445213: Homeownership rate, 2009-2013\n",
    "HSG096213: Housing units in multi-unit structures, percent, 2009-2013\n",
    "HSG495213: Median value of owner-occupied housing units, 2009-2013\n",
    "HSD410213: Households, 2009-2013\n",
    "HSD310213: Persons per household, 2009-2013\n",
    "INC910213: Per capita money income in past 12 months (2013 dollars), 2009-2013\n",
    "INC110213: Median household income, 2009-2013\n",
    "PVY020213: Persons below poverty level, percent, 2009-2013\n",
    "BZA010213: Private nonfarm establishments, 2013\n",
    "BZA110213: Private nonfarm employment,  2013\n",
    "BZA115213: Private nonfarm employment, percent change, 2012-2013\n",
    "NES010213: Nonemployer establishments, 2013\n",
    "SBO001207: Total number of firms, 2007\n",
    "SBO315207: Black-owned firms, percent, 2007\n",
    "SBO115207: American Indian- and Alaska Native-owned firms, percent, 2007\n",
    "SBO215207: Asian-owned firms, percent, 2007\n",
    "SBO515207: Native Hawaiian- and Other Pacific Islander-owned firms, percent, 2007\n",
    "SBO415207: Hispanic-owned firms, percent, 2007\n",
    "SBO015207: Women-owned firms, percent, 2007\n",
    "MAN450207: Manufacturers shipments, 2007 ($1,000)\n",
    "WTN220207: Merchant wholesaler sales, 2007 ($1,000)\n",
    "RTN130207: Retail sales, 2007 ($1,000)\n",
    "RTN131207: Retail sales per capita, 2007\n",
    "AFN120207: Accommodation and food services sales, 2007 ($1,000)\n",
    "BPS030214: Building permits, 2014\n",
    "LND110210: Land area in square miles, 2010\n",
    "POP060210: Population per square mile, 2010\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data...done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>total_votes_2012</th>\n",
       "      <th>votes_dem_2012</th>\n",
       "      <th>votes_gop_2012</th>\n",
       "      <th>Obama</th>\n",
       "      <th>Romney</th>\n",
       "      <th>PST045214</th>\n",
       "      <th>PST040210</th>\n",
       "      <th>PST120214</th>\n",
       "      <th>POP010210</th>\n",
       "      <th>...</th>\n",
       "      <th>SBO415207</th>\n",
       "      <th>SBO015207</th>\n",
       "      <th>MAN450207</th>\n",
       "      <th>WTN220207</th>\n",
       "      <th>RTN130207</th>\n",
       "      <th>RTN131207</th>\n",
       "      <th>AFN120207</th>\n",
       "      <th>BPS030214</th>\n",
       "      <th>LND110210</th>\n",
       "      <th>POP060210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IA</td>\n",
       "      <td>4804</td>\n",
       "      <td>2369</td>\n",
       "      <td>2373</td>\n",
       "      <td>0.493131</td>\n",
       "      <td>0.493963</td>\n",
       "      <td>9200</td>\n",
       "      <td>9337</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>9336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>144862</td>\n",
       "      <td>87923</td>\n",
       "      <td>9258</td>\n",
       "      <td>3859</td>\n",
       "      <td>6</td>\n",
       "      <td>569.57</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GA</td>\n",
       "      <td>7757</td>\n",
       "      <td>1499</td>\n",
       "      <td>6112</td>\n",
       "      <td>0.193245</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>22264</td>\n",
       "      <td>22084</td>\n",
       "      <td>0.8</td>\n",
       "      <td>22084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>430397</td>\n",
       "      <td>107788</td>\n",
       "      <td>315062</td>\n",
       "      <td>14431</td>\n",
       "      <td>22760</td>\n",
       "      <td>2</td>\n",
       "      <td>261.50</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NC</td>\n",
       "      <td>50353</td>\n",
       "      <td>18115</td>\n",
       "      <td>31695</td>\n",
       "      <td>0.359760</td>\n",
       "      <td>0.629456</td>\n",
       "      <td>187589</td>\n",
       "      <td>177772</td>\n",
       "      <td>5.5</td>\n",
       "      <td>177772</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>253035</td>\n",
       "      <td>96946</td>\n",
       "      <td>1913882</td>\n",
       "      <td>11698</td>\n",
       "      <td>287943</td>\n",
       "      <td>1081</td>\n",
       "      <td>762.74</td>\n",
       "      <td>233.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TX</td>\n",
       "      <td>813</td>\n",
       "      <td>109</td>\n",
       "      <td>700</td>\n",
       "      <td>0.134071</td>\n",
       "      <td>0.861009</td>\n",
       "      <td>1608</td>\n",
       "      <td>1641</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3416</td>\n",
       "      <td>6813</td>\n",
       "      <td>4195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>912.55</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KS</td>\n",
       "      <td>4955</td>\n",
       "      <td>1393</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.281130</td>\n",
       "      <td>0.705348</td>\n",
       "      <td>23465</td>\n",
       "      <td>22952</td>\n",
       "      <td>2.2</td>\n",
       "      <td>22952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0</td>\n",
       "      <td>197478</td>\n",
       "      <td>314598</td>\n",
       "      <td>13898</td>\n",
       "      <td>32249</td>\n",
       "      <td>62</td>\n",
       "      <td>639.50</td>\n",
       "      <td>35.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_abbr  total_votes_2012  votes_dem_2012  votes_gop_2012     Obama  \\\n",
       "0         IA              4804            2369            2373  0.493131   \n",
       "1         GA              7757            1499            6112  0.193245   \n",
       "2         NC             50353           18115           31695  0.359760   \n",
       "3         TX               813             109             700  0.134071   \n",
       "4         KS              4955            1393            3495  0.281130   \n",
       "\n",
       "     Romney  PST045214  PST040210  PST120214  POP010210  ...  SBO415207  \\\n",
       "0  0.493963       9200       9337       -1.5       9336  ...        0.0   \n",
       "1  0.787933      22264      22084        0.8      22084  ...        0.0   \n",
       "2  0.629456     187589     177772        5.5     177772  ...        0.0   \n",
       "3  0.861009       1608       1641       -2.0       1641  ...        0.0   \n",
       "4  0.705348      23465      22952        2.2      22952  ...        0.0   \n",
       "\n",
       "   SBO015207  MAN450207  WTN220207  RTN130207  RTN131207  AFN120207  \\\n",
       "0       23.1          0     144862      87923       9258       3859   \n",
       "1       25.3     430397     107788     315062      14431      22760   \n",
       "2       29.0     253035      96946    1913882      11698     287943   \n",
       "3        0.0          0       3416       6813       4195          0   \n",
       "4       19.2          0     197478     314598      13898      32249   \n",
       "\n",
       "   BPS030214  LND110210  POP060210  \n",
       "0          6     569.57       16.4  \n",
       "1          2     261.50       84.5  \n",
       "2       1081     762.74      233.1  \n",
       "3          0     912.55        1.8  \n",
       "4         62     639.50       35.9  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "print('Reading the data...', end='')\n",
    "df = pd.read_csv('vote16_classification.csv')\n",
    "print('done!')\n",
    "\n",
    "y = df.iloc[:,0]\n",
    "X = df.iloc[:,1:]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to decide how to handle the state abbreviation, which is a categorical variable.  Solutions include\n",
    "* one-hot encoding,\n",
    "* categorical encoding, and\n",
    "* dropping this feature from the data.\n",
    "\n",
    "Whatever you do should be incorporated in your classification pipeline so I can reproduce your results on my test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The First step for this project was determining which classifier would work best. For this step, I decided to try them all, and with the comments in the code below my results may be observed. The biggest takeaway from the results was that because RandomForests performed the best, and it had more hyperparameters, it seemed like a natural fit for my classifier of choice. Through minor changes, I figured it would be easy to squeeze more accuracy out of this classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sammy Martinez\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Confusion Matrix:\n",
      " [[ 67   9]\n",
      " [  3 321]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92        76\n",
      "         1.0       0.97      0.99      0.98       324\n",
      "\n",
      "    accuracy                           0.97       400\n",
      "   macro avg       0.96      0.94      0.95       400\n",
      "weighted avg       0.97      0.97      0.97       400\n",
      "\n",
      "Model saved as random_forest_voting_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sammy Martinez\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.9625 0.9725 0.965  0.97   0.975 ]\n",
      "Mean cross-validation score: 0.969\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "# Load the data\n",
    "data = pd.read_csv('vote16_classification.csv')  # Replace with your actual data file\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['label'])  # Replace 'vote' with your actual target column name\n",
    "y = data['label']  # Assuming 'vote' is 0 for Clinton and 1 for Trump\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#'num' transformer: fills in missing values with SimpleImputer\n",
    "# 'cat' Deals with categorical feature, 'state_abbr', using OneHotEncoder\n",
    "# Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), X.select_dtypes(include=['int64', 'float64']).columns),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), X.select_dtypes(include=['object']).columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Random Forest:\n",
    "# SVM - took WAY too long to train\n",
    "# decision trees - .965\n",
    "# Linear Discriminant  Analysis - .955\n",
    "# quadratic discriminant Analysis - .925\n",
    "# logistic regression - .95\n",
    "# random forests - .9675, n_estimators = 200, random_state = 39\n",
    "# k nearest Neighbors - .85 horrible\n",
    "#decision OR random Forests\n",
    "#decision\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    #('scaler', StandardScaler()), Scaling is NOT necessary for Trees!\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200,random_state=39))\n",
    "\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#Saving model\n",
    "import joblib\n",
    "joblib.dump(pipeline, 'random_forest_voting_model.pkl')\n",
    "print('Model saved as random_forest_voting_model.pkl')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean cross-validation score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do\n",
    "\n",
    "* Build a classifier that predicts how a county votes with at least 98% overall accuracy.  It isn't too difficult to obtain 98% overall accuracy, and at least 95% accuracy for each candidate.  More accurate is better for this problem.\n",
    "* Populate this Jupyter notebook with the code needed to create, train, and run your classifier.\n",
    "    * As part of your model evaluation, your notebook should compute and print the confusion matrix and other measures of accuracy.\n",
    "    * The notebook will also serve for you to include a discussion of what you did.\n",
    "        - What classifiers did you try?  \n",
    "        - What tuning did you do?\n",
    "        - How did the classifiers perform?  You might want to look at [this discussion of model evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html) in Scikit-Learn.\n",
    "        - How did you settle on your final choice of classifier?\n",
    "        - Do you have any sense of what the classifier is doing?  e.g., what are the most important features?\n",
    "* You should build your classifier and any preprocessing as a scikit-learn <code>Pipeline</code>.\n",
    "* You should save your classification pipeline to the file <code>vote16_clf.pkl</code> using <code>sklearn.externals.joblib</code> (see below).\n",
    "* If you use a grid search or random search for hyperparameter tuning, you should indicate this in the write-up below, and submit the hyperparameters used in the submitted solution (you can just specify them in calls to the classifier's constructor).\n",
    "* If you try a classifier and it does not work to your liking, you should indicate this.  You can leave the code in the notebook, commented out, so I can see what you tried.\n",
    "\n",
    "* You can choose from any of the classifiers we have studied (other than neural networks), including\n",
    " - [k nearest neighbors](http://scikit-learn.org/stable/modules/neighbors.html),\n",
    " - [support vector machines / kernel machines](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html),\n",
    " - [decision trees](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier),\n",
    " - [Linear discriminant analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis)\n",
    " -  [quadratic discriminant analysis](https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis)\n",
    " - [logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html),\n",
    " - [support vector and kernel classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    " - ensembles of the preceding (e.g., [random forests](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [AdaBoosted collections of weak learners](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)),\n",
    " \n",
    "## Note\n",
    "\n",
    "In order to build a pipeline you will may need to implement your own first step of the pipeline in order to perform feature selection and any necessary feature encoding.  You can do so by creating your own class with a <code>fit()</code> and <code>transform()</code> method.  \n",
    "\n",
    "The calling sequences and return sequences of these two methods should be the same as those of the StandardScaler [<code>fit()</code>](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit) and [<code>transform()</code>](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.transform).\n",
    "\n",
    "For example, <code>fit()</code> might not do anything while <code>transform()</code> will return a subset of the variables as a numpy array.\n",
    "\n",
    "For full credit your pipeline should encapsulate all of your preprocessing steps.  If you cannot figure out how to make this work, you can enter your preprocessing steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to submit\n",
    "\n",
    "1. This Jupyter notebook, filled out with code that when run will produce a working classifer with all necessary preprocessing.\n",
    "    * You should use your final hyperparameter values in the call to the classifier's constructor.\n",
    "2. If you get the pipeline working, the resulting <code>.pkl</code> file as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sammy Martinez\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Confusion Matrix:\n",
      " [[ 74   2]\n",
      " [  6 318]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95        76\n",
      "         1.0       0.99      0.98      0.99       324\n",
      "\n",
      "    accuracy                           0.98       400\n",
      "   macro avg       0.96      0.98      0.97       400\n",
      "weighted avg       0.98      0.98      0.98       400\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the classifier...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('vote16_classification.csv')  # Replace with your actual data file\n",
    "\n",
    "# Define features and target\n",
    "#X = data.drop(columns=['label'])  # Replace 'label' with your actual target column name\n",
    "#X = data.drop(columns=['label'])\n",
    "#X=data\n",
    "X = data.drop(columns=['label'])\n",
    "\n",
    "y = data['label']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#Unable to get to work\n",
    "class Drop_Column_2(BaseEstimator,TransformerMixin):\n",
    "    def fit(self, X=None, y=None, sample_weight=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "          return X.iloc[:, 1:] \n",
    "class Drop_Column_1(BaseEstimator,TransformerMixin):\n",
    "    def fit(self, X=None, y=None, sample_weight=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, copy=None):\n",
    "        return X.iloc[:,1:]\n",
    "    \n",
    "# Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('drop', Drop_Column_1(), X.columns),\n",
    "        ('number_editing', SimpleImputer(strategy='mean'), X.select_dtypes(include=['int64', 'float64']).columns),\n",
    "        ('categorical_Data', OneHotEncoder(drop='first', handle_unknown='ignore'), X.select_dtypes(include=['object']).columns)\n",
    "    ]\n",
    ")\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "#Preprocessing\n",
    "X_train_processed = pipeline.fit_transform(X_train)\n",
    "X_test_processed = pipeline.transform(X_test)\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Smote \n",
    "smote = SMOTE(random_state=100)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)\n",
    "\n",
    " #Training model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, random_state=39)\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Clinton', 'Trump'], yticklabels=['Clinton', 'Trump'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "#Saving classifier\n",
    "import dill\n",
    "print('Saving the classifier...')\n",
    "with open('vote16_classifier.dill', 'wb') as file:\n",
    "    dill.dump(rf_classifier, file)\n",
    "with open('vote16_classifier.dill', 'rb') as file:\n",
    "    loaded_rf_classifier = dill.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To squeeze more accuracy out of the model, I applited the SMOTE algorithm. As stated in this project description, there is a class inbalance between the counties who voted Clinton, and the counties who voted for Trump. SMOTE creates artificial members of the lower class to pad the data and to make the model more immune to class inbalances. In the case of the RandomForest classifier, I found that it was able to squeeze more performance out of the model. \n",
    "\n",
    "Class inbalance is an integral aspect of classifiers, as rudimentary algorithms will give fantastic results!...given that the majority class is an easy guess with a 9:1 ratio. Algorithms that deal with class inbalance may be particularly useful for such skewed datasets. \n",
    "\n",
    "Note about the pipeline: Unable to combine certain steps with the pipeline. Steps not included in the pipeline: dropping the first column, splitting the data, applying the SMOTE algorithm. The SMOTE algorithm requires 2 parameters, and I was unable to get this to work. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
